{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 추론 시간 재기(Inference Time)"
      ],
      "metadata": {
        "id": "AEbGXTdWWHUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## openvino모델의 추론시간(Geti)"
      ],
      "metadata": {
        "id": "LtJIOAdsWiBl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFBlxtgFVVYi",
        "outputId": "a75c029f-a863-4bb1-8e4f-c5ddede79b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!python -m pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openvino"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd37P-RrWLdb",
        "outputId": "a3d894f1-df42-4e60-a04b-ea7d47c337d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openvino in /usr/local/lib/python3.10/dist-packages (2023.2.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from openvino) (1.23.5)\n",
            "Requirement already satisfied: openvino-telemetry>=2023.2.1 in /usr/local/lib/python3.10/dist-packages (from openvino) (2023.2.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"from openvino.runtime import Core\""
      ],
      "metadata": {
        "id": "91-HQhZjWL7q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openvino.runtime import Core\n",
        "from pathlib import Path\n",
        "\n",
        "model_path = \"openvino.xml\"\n",
        "ie = Core() # initialize inference engine\n",
        "network = ie.read_model(model=model_path, weights=Path(model_path).with_suffix('.bin'))\n",
        "executable_network = ie.compile_model(model=network, device_name=\"CPU\")"
      ],
      "metadata": {
        "id": "P-IrLKySWNUM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "im = np.random.randn(1,3,224, 224) #random input\n",
        "output_layer = next(iter(executable_network.outputs)) # OpenVINO model의 output layer를 가져옴\n",
        "y = executable_network([im])[output_layer] # Inference 실행하여 output_layer에 해당하는 output을 y에 할당"
      ],
      "metadata": {
        "id": "mFi6lGyQWYto"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "y = executable_network([im]) [output_layer]\n",
        "print(f'time lapse: {time.time()-start}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUh6ifASWaLJ",
        "outputId": "b5cc9d43-3a8c-4f7b-a45b-8540ebf4852a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time lapse: 0.03080296516418457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## onnx모델의 추론시간(Geti)"
      ],
      "metadata": {
        "id": "8fB0JGhtWcfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JClChUDWb8s",
        "outputId": "921d0273-d9bb-4ffe-b3e4-00585cc8a5c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.15.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz5DnHmNWu-Y",
        "outputId": "c187da28-ac30-4f04-d3e3-501a90be482f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m544.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.16.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q \"openvino>=2023.1.0\" \"nncf>=2.6.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8VrXQOgWxrT",
        "outputId": "54abbeb7-3e6a-4cc1-a536-821b5839f9d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.7/120.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.4/68.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for jstyleson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for grapheme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### onnx모델을 openvino로 변환"
      ],
      "metadata": {
        "id": "e9q2-uNsXzHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "import openvino as ov\n",
        "\n",
        "onnx_path = \"model.onnx\"\n",
        "ir_path = \"model.xml\"\n",
        "\n",
        "ov_model = ov.convert_model(onnx_path)\n",
        "ov.save_model(ov_model, ir_path)"
      ],
      "metadata": {
        "id": "HVHi73hrXJtH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### onnx모델이 한 프레임을 추론하는 시간"
      ],
      "metadata": {
        "id": "z06AtmgMX9Fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import onnxruntime\n",
        "import time\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_model_path = \"model.onnx\"\n",
        "ort_session = onnxruntime.InferenceSession(onnx_model_path)\n",
        "\n",
        "# Get the name of the input node\n",
        "input_name = ort_session.get_inputs()[0].name\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture('input_video.avi')\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if ret:\n",
        "        # Preprocess the frame to match the model's input shape\n",
        "        frame = cv2.resize(frame, (224, 224))  # 예: 모델이 224x224 크기의 이미지를 입력으로 받는 경우\n",
        "        input_data = np.array(frame).astype('float32')\n",
        "\n",
        "        # 모델의 입력 차원에 맞게 배열을 재구성합니다.\n",
        "        # 예: 모델이 배치 크기 x 채널 수 x 높이 x 너비 형식의 입력을 받는 경우\n",
        "        input_data = input_data.transpose((2, 0, 1))  # HWC to CHW\n",
        "        input_data = np.expand_dims(input_data, axis=0)  # Add batch dimension\n",
        "\n",
        "        # Measure the inference time\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Perform inference using the ONNX model\n",
        "        output = ort_session.run(None, {input_name: input_data})\n",
        "\n",
        "        inference_time = time.time() - start_time\n",
        "        print(\"Inference Time:\", inference_time)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cap.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLrZmVuDXHnS",
        "outputId": "48b3a42b-d824-4ac8-dd11-ca3c9a96d146"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 0.046550750732421875\n",
            "Inference Time: 0.04324650764465332\n",
            "Inference Time: 0.04508686065673828\n",
            "Inference Time: 0.04114651679992676\n",
            "Inference Time: 0.04578685760498047\n",
            "Inference Time: 0.0456695556640625\n",
            "Inference Time: 0.041831016540527344\n",
            "Inference Time: 0.04325556755065918\n",
            "Inference Time: 0.04779672622680664\n",
            "Inference Time: 0.043607234954833984\n",
            "Inference Time: 0.04755234718322754\n",
            "Inference Time: 0.044660091400146484\n",
            "Inference Time: 0.04666900634765625\n",
            "Inference Time: 0.043031930923461914\n",
            "Inference Time: 0.042578697204589844\n",
            "Inference Time: 0.04341435432434082\n",
            "Inference Time: 0.05155587196350098\n",
            "Inference Time: 0.04413557052612305\n",
            "Inference Time: 0.043572425842285156\n",
            "Inference Time: 0.04198598861694336\n",
            "Inference Time: 0.04214811325073242\n",
            "Inference Time: 0.04273176193237305\n",
            "Inference Time: 0.04200005531311035\n",
            "Inference Time: 0.043015480041503906\n",
            "Inference Time: 0.04578661918640137\n",
            "Inference Time: 0.0432438850402832\n",
            "Inference Time: 0.04209113121032715\n",
            "Inference Time: 0.041351318359375\n",
            "Inference Time: 0.0426177978515625\n",
            "Inference Time: 0.04228782653808594\n",
            "Inference Time: 0.04328012466430664\n",
            "Inference Time: 0.04364514350891113\n",
            "Inference Time: 0.04079389572143555\n",
            "Inference Time: 0.04132437705993652\n",
            "Inference Time: 0.042394399642944336\n",
            "Inference Time: 0.04129147529602051\n",
            "Inference Time: 0.04187822341918945\n",
            "Inference Time: 0.04185986518859863\n",
            "Inference Time: 0.04181241989135742\n",
            "Inference Time: 0.048309326171875\n",
            "Inference Time: 0.0423426628112793\n",
            "Inference Time: 0.04227185249328613\n",
            "Inference Time: 0.043065547943115234\n",
            "Inference Time: 0.04276752471923828\n",
            "Inference Time: 0.042176246643066406\n",
            "Inference Time: 0.04421734809875488\n",
            "Inference Time: 0.04429197311401367\n",
            "Inference Time: 0.04219388961791992\n",
            "Inference Time: 0.05247950553894043\n",
            "Inference Time: 0.042511940002441406\n",
            "Inference Time: 0.0435941219329834\n",
            "Inference Time: 0.048219919204711914\n",
            "Inference Time: 0.04630160331726074\n",
            "Inference Time: 0.042565345764160156\n",
            "Inference Time: 0.04332137107849121\n",
            "Inference Time: 0.04309964179992676\n",
            "Inference Time: 0.04216337203979492\n",
            "Inference Time: 0.043207406997680664\n",
            "Inference Time: 0.042928218841552734\n",
            "Inference Time: 0.04087400436401367\n",
            "Inference Time: 0.04092001914978027\n",
            "Inference Time: 0.04355287551879883\n",
            "Inference Time: 0.040818214416503906\n",
            "Inference Time: 0.04132342338562012\n",
            "Inference Time: 0.04259204864501953\n",
            "Inference Time: 0.04084920883178711\n",
            "Inference Time: 0.04659914970397949\n",
            "Inference Time: 0.04231524467468262\n",
            "Inference Time: 0.042724609375\n",
            "Inference Time: 0.04268002510070801\n",
            "Inference Time: 0.04288959503173828\n",
            "Inference Time: 0.041220664978027344\n",
            "Inference Time: 0.04340243339538574\n",
            "Inference Time: 0.04323267936706543\n",
            "Inference Time: 0.04302072525024414\n",
            "Inference Time: 0.043556928634643555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### onnx모델이 한 동영상을 추론하는 총 시간"
      ],
      "metadata": {
        "id": "oO3WzqHuX0-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install collection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdK6ktZOXcHz",
        "outputId": "8d144ddc-434d-4111-dbf2-684d790bb612"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting collection\n",
            "  Downloading collection-0.1.6.tar.gz (5.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: collection\n",
            "  Building wheel for collection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for collection: filename=collection-0.1.6-py3-none-any.whl size=5099 sha256=15b7d4640d8b79a1102726d301f38431d0d162ed57bb09a295fd6788ba6f210c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/70/eb/1d28795e9384ab3b9be6359bdde9e1652f6e7dab9d26844f70\n",
            "Successfully built collection\n",
            "Installing collected packages: collection\n",
            "Successfully installed collection-0.1.6\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import onnxruntime\n",
        "import time\n",
        "from collections import Counter\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_model_path = \"model.onnx\"\n",
        "ort_session = onnxruntime.InferenceSession(onnx_model_path)\n",
        "\n",
        "# Get the name of the input node\n",
        "input_name = ort_session.get_inputs()[0].name\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture('input_video.avi')\n",
        "\n",
        "# List to store inference results\n",
        "results = []\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if ret:\n",
        "        # Preprocess the frame to match the model's input shape\n",
        "        frame = cv2.resize(frame, (224, 224))  # 예: 모델이 224x224 크기의 이미지를 입력으로 받는 경우\n",
        "        input_data = np.array(frame).astype('float32')\n",
        "\n",
        "        # 모델의 입력 차원에 맞게 배열을 재구성합니다.\n",
        "        # 예: 모델이 배치 크기 x 채널 수 x 높이 x 너비 형식의 입력을 받는 경우\n",
        "        input_data = input_data.transpose((2, 0, 1))  # HWC to CHW\n",
        "        input_data = np.expand_dims(input_data, axis=0)  # Add batch dimension\n",
        "\n",
        "        # Perform inference using the ONNX model\n",
        "        output = ort_session.run(None, {input_name: input_data})\n",
        "\n",
        "        # Store the result\n",
        "        results.append(tuple(output[0].flatten().tolist()))\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# Find the most common result\n",
        "counter = Counter(results)\n",
        "most_common_result = counter.most_common(1)[0][0]\n",
        "\n",
        "print(\"Most Common Result:\", most_common_result)\n",
        "\n",
        "# Measure the time to the most common result\n",
        "start_time = time.time()\n",
        "while most_common_result not in results:\n",
        "    time.sleep(0.01)\n",
        "time_to_most_common = time.time() - start_time\n",
        "\n",
        "print(\"Time to Most Common Result:\", time_to_most_common)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZizcrOVXevi",
        "outputId": "59736f56-ae85-4565-b6c5-bd82f611fb34"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Common Result: (0.23193198442459106, -0.4557848870754242, 0.22414630651474)\n",
            "Time to Most Common Result: 9.72747802734375e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pytorch모델의 추론시간(Geti)"
      ],
      "metadata": {
        "id": "ztfR87oZYGz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT2iGv6xYTzp",
        "outputId": "5c7e69dd-396a-4889-ddfc-5e0906d7977e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Load the PyTorch model\n",
        "model_path = \"weights.pth\"\n",
        "model = torch.load(model_path)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Create a random input\n",
        "im = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "# Measure the inference time\n",
        "start = time.time()\n",
        "y = model(im)\n",
        "print(f'time lapse: {time.time()-start}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "u5bGQVcDYWU1",
        "outputId": "afe812cd-cb53-4583-eb54-0613e00de9fd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-4effd00ee76d>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the PyTorch model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"weights.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set the model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m                 return _load(opened_zipfile,\n\u001b[0m\u001b[1;32m   1015\u001b[0m                              \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                              \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m         typed_storage = torch.storage.TypedStorage(\n\u001b[0;32m-> 1366\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1367\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m             _internal=True)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    259\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ]
    }
  ]
}